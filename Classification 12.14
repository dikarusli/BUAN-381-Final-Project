library(dplyr)
library(caret)      # For confusionMatrix() and data partitioning
library(broom)      # For glance() and tidy()
library(MASS)       # For lm.ridge()
library(ggplot2)    # For ggplot()
library(mgcv)       # For gam()
library(rsample)    # For initial_split() stratified random sampling
library(e1071)      # SVM library
library(pROC)       # For ROC and AUC
library(tidymodels) # For ROC curve plotting with yardstick

df <- read.csv('https://raw.githubusercontent.com/dikarusli/BUAN-381-Final-Project/refs/heads/main/BUAN-381-Dataset.csv')

# Convert the response variable 'SOUSED' to a factor
df$SOUSED <- factor(df$SOUSED, levels = c(0, 1), labels = c("No", "Yes"))

# Quick Data Analysis
print(colnames(df))
print(anyNA(df))
summary(df)

# Correlation analysis
numeric_vars <- df %>% select_if(is.numeric)
cor_matrix <- cor(numeric_vars)
print(cor_matrix)

# Set the seed for reproducibility
set.seed(123)

split <- initial_split(df, prop = 0.7, strata = SOUSED)
Train <- training(split)
Temp <- testing(split)

# Temp into Validation and Test sets (each 15% of the total data)
validation_test_split <- initial_split(Temp, prop = 0.5, strata = SOUSED)
Valid <- training(validation_test_split)
Test <- testing(validation_test_split)

# Dimensions of partitioned data
print(dim(Train))
print(dim(Valid))
print(dim(Test))

# Logistic regression model using the training set
logit_model <- glm(SOUSED ~ ., data = Train, family = binomial(link = "logit"))

# Summary of the logit model
summary(logit_model)

# Predict probabilities on the validation set
valid_logit_probs <- predict(logit_model, newdata = Valid, type = "response")

# Convert probabilities to binary outcomes using a 0.5 threshold
valid_logit_pred <- ifelse(valid_logit_probs > 0.5, "Yes", "No")
valid_logit_pred <- factor(valid_logit_pred, levels = c("No", "Yes"))

# Confusion Matrix using caret
conf_matrix_logit <- confusionMatrix(valid_logit_pred, Valid$SOUSED, positive = "Yes")
print(conf_matrix_logit)

# ROC Curve and AUC for Logit Model
roc_logit <- roc(Valid$SOUSED, valid_logit_probs, levels = c("No", "Yes"))
plot(roc_logit, main = "ROC Curve for Logistic Regression (Logit)", col = "blue", lwd = 2)
auc_logit <- auc(roc_logit)
print(paste("Logit Validation AUC:", round(auc_logit, 3)))

# Build the probit regression model using the training set
probit_model <- glm(SOUSED ~ ., data = Train, family = binomial(link = "probit"))

# Summary of the probit model
summary(probit_model)

# Predict probabilities on the validation set using the probit model
valid_probit_probs <- predict(probit_model, newdata = Valid, type = "response")

# Convert probabilities to binary outcomes using a 0.5 threshold
valid_probit_pred <- ifelse(valid_probit_probs > 0.5, "Yes", "No")
valid_probit_pred <- factor(valid_probit_pred, levels = c("No", "Yes"))

# Confusion Matrix using caret for Probit Model
conf_matrix_probit <- confusionMatrix(valid_probit_pred, Valid$SOUSED, positive = "Yes")
print(conf_matrix_probit)

# ROC Curve and AUC for Probit Model
roc_probit <- roc(Valid$SOUSED, valid_probit_probs, levels = c("No", "Yes"))
plot(roc_probit, main = "ROC Curve for Probit Model", col = "red", lwd = 2)
auc_probit <- auc(roc_probit)
print(paste("Probit Validation AUC:", round(auc_probit, 3)))

test_logit_probs <- predict(logit_model, newdata = Test, type = "response")
test_logit_pred <- ifelse(test_logit_probs > 0.5, "Yes", "No")
test_logit_pred <- factor(test_logit_pred, levels = c("No", "Yes"))

conf_matrix_test_logit <- confusionMatrix(test_logit_pred, Test$SOUSED, positive = "Yes")
print(conf_matrix_test_logit)

roc_test_logit <- roc(Test$SOUSED, test_logit_probs, levels = c("No", "Yes"))
plot(roc_test_logit, main = "ROC Curve for Logit Model on Test Set", col = "green", lwd = 2)
auc_test_logit <- auc(roc_test_logit)
print(paste("Logit Test AUC:", round(auc_test_logit, 3)))

library(dplyr)
library(caret)      # For confusionMatrix() and data partitioning
library(broom)      # For glance() and tidy()
library(MASS)       # For lm.ridge()
library(ggplot2)    # For ggplot()
library(mgcv)       # For gam()
library(rsample)    # For initial_split() stratified random sampling
library(e1071)      # SVM library
library(pROC)       # For ROC and AUC
library(tidymodels) # For ROC curve plotting with yardstick

df <- read.csv('https://raw.githubusercontent.com/dikarusli/BUAN-381-Final-Project/refs/heads/main/BUAN-381-Dataset.csv')

# Convert the response variable 'SOUSED' to a factor
df$SOUSED <- factor(df$SOUSED, levels = c(0, 1), labels = c("No", "Yes"))

# Quick Data Analysis
print(colnames(df))
print(anyNA(df))
summary(df)

# Correlation analysis
numeric_vars <- df %>% select_if(is.numeric)
cor_matrix <- cor(numeric_vars)
print(cor_matrix)

# Set the seed for reproducibility
set.seed(123)

split <- initial_split(df, prop = 0.7, strata = SOUSED)
Train <- training(split)
Temp <- testing(split)

# Temp into Validation and Test sets (each 15% of the total data)
validation_test_split <- initial_split(Temp, prop = 0.5, strata = SOUSED)
Valid <- training(validation_test_split)
Test <- testing(validation_test_split)

# Dimensions of partitioned data
print(dim(Train))
print(dim(Valid))
print(dim(Test))

# Logistic regression model using the training set
logit_model <- glm(SOUSED ~ ., data = Train, family = binomial(link = "logit"))

# Summary of the logit model
summary(logit_model)

# Predict probabilities on the validation set
valid_logit_probs <- predict(logit_model, newdata = Valid, type = "response")

# Convert probabilities to binary outcomes using a 0.5 threshold
valid_logit_pred <- ifelse(valid_logit_probs > 0.5, "Yes", "No")
valid_logit_pred <- factor(valid_logit_pred, levels = c("No", "Yes"))

# Confusion Matrix using caret
conf_matrix_logit <- confusionMatrix(valid_logit_pred, Valid$SOUSED, positive = "Yes")
print(conf_matrix_logit)

# ROC Curve and AUC for Logit Model
roc_logit <- roc(Valid$SOUSED, valid_logit_probs, levels = c("No", "Yes"))
plot(roc_logit, main = "ROC Curve for Logistic Regression (Logit)", col = "blue", lwd = 2)
auc_logit <- auc(roc_logit)
print(paste("Logit Validation AUC:", round(auc_logit, 3)))

# Build the probit regression model using the training set
probit_model <- glm(SOUSED ~ ., data = Train, family = binomial(link = "probit"))

# Summary of the probit model
summary(probit_model)

# Predict probabilities on the validation set using the probit model
valid_probit_probs <- predict(probit_model, newdata = Valid, type = "response")

# Convert probabilities to binary outcomes using a 0.5 threshold
valid_probit_pred <- ifelse(valid_probit_probs > 0.5, "Yes", "No")
valid_probit_pred <- factor(valid_probit_pred, levels = c("No", "Yes"))

# Confusion Matrix using caret for Probit Model
conf_matrix_probit <- confusionMatrix(valid_probit_pred, Valid$SOUSED, positive = "Yes")
print(conf_matrix_probit)

# ROC Curve and AUC for Probit Model
roc_probit <- roc(Valid$SOUSED, valid_probit_probs, levels = c("No", "Yes"))
plot(roc_probit, main = "ROC Curve for Probit Model", col = "red", lwd = 2)
auc_probit <- auc(roc_probit)
print(paste("Probit Validation AUC:", round(auc_probit, 3)))

test_logit_probs <- predict(logit_model, newdata = Test, type = "response")
test_logit_pred <- ifelse(test_logit_probs > 0.5, "Yes", "No")
test_logit_pred <- factor(test_logit_pred, levels = c("No", "Yes"))

conf_matrix_test_logit <- confusionMatrix(test_logit_pred, Test$SOUSED, positive = "Yes")
print(conf_matrix_test_logit)

roc_test_logit <- roc(Test$SOUSED, test_logit_probs, levels = c("No", "Yes"))
plot(roc_test_logit, main = "ROC Curve for Logit Model on Test Set", col = "green", lwd = 2)
auc_test_logit <- auc(roc_test_logit)
print(paste("Logit Test AUC:", round(auc_test_logit, 3)))

# Load necessary libraries (ensure all packages are installed)
library(dplyr)
library(caret)      # For confusionMatrix()
library(e1071)      # For SVM
library(rpart)      # For classification tree
library(rpart.plot) # For visualizing decision trees
library(randomForest) # For random forest ensemble
library(pROC)       # For ROC and AUC

# Support Vector Machine (SVM)
set.seed(123)
svm_model <- svm(SOUSED ~ ., data = Train, kernel = "linear", probability = TRUE)

# Predict probabilities on the validation set
valid_svm_probs <- predict(svm_model, newdata = Valid, probability = TRUE)
valid_svm_probs <- attr(valid_svm_probs, "probabilities")[, "Yes"]

# Convert probabilities to binary outcomes using a 0.5 threshold
valid_svm_pred <- ifelse(valid_svm_probs > 0.5, "Yes", "No")
valid_svm_pred <- factor(valid_svm_pred, levels = c("No", "Yes"))

# Confusion Matrix for SVM
conf_matrix_svm <- confusionMatrix(valid_svm_pred, Valid$SOUSED, positive = "Yes")
print(conf_matrix_svm)

# ROC Curve and AUC for SVM
roc_svm <- roc(Valid$SOUSED, valid_svm_probs, levels = c("No", "Yes"))
plot(roc_svm, main = "ROC Curve for SVM", col = "purple", lwd = 2)
auc_svm <- auc(roc_svm)
print(paste("SVM Validation AUC:", round(auc_svm, 3)))

# Classification Tree
set.seed(123)
tree_model <- rpart(SOUSED ~ ., data = Train, method = "class")

# Plot the decision tree
rpart.plot(tree_model, main = "Classification Tree")

# Predict probabilities on the validation set
valid_tree_probs <- predict(tree_model, newdata = Valid, type = "prob")[, "Yes"]

# Convert probabilities to binary outcomes using a 0.5 threshold
valid_tree_pred <- ifelse(valid_tree_probs > 0.5, "Yes", "No")
valid_tree_pred <- factor(valid_tree_pred, levels = c("No", "Yes"))

# Confusion Matrix for Classification Tree
conf_matrix_tree <- confusionMatrix(valid_tree_pred, Valid$SOUSED, positive = "Yes")
print(conf_matrix_tree)

# ROC Curve and AUC for Classification Tree
roc_tree <- roc(Valid$SOUSED, valid_tree_probs, levels = c("No", "Yes"))
plot(roc_tree, main = "ROC Curve for Classification Tree", col = "orange", lwd = 2)
auc_tree <- auc(roc_tree)
print(paste("Tree Validation AUC:", round(auc_tree, 3)))

# Tree-Based Ensemble Model (Random Forest)
set.seed(123)
rf_model <- randomForest(SOUSED ~ ., data = Train, ntree = 100, importance = TRUE)

# Predict probabilities on the validation set
valid_rf_probs <- predict(rf_model, newdata = Valid, type = "prob")[, "Yes"]

# Convert probabilities to binary outcomes using a 0.5 threshold
valid_rf_pred <- ifelse(valid_rf_probs > 0.5, "Yes", "No")
valid_rf_pred <- factor(valid_rf_pred, levels = c("No", "Yes"))

# Confusion Matrix for Random Forest
conf_matrix_rf <- confusionMatrix(valid_rf_pred, Valid$SOUSED, positive = "Yes")
print(conf_matrix_rf)

# ROC Curve and AUC for Random Forest
roc_rf <- roc(Valid$SOUSED, valid_rf_probs, levels = c("No", "Yes"))
plot(roc_rf, main = "ROC Curve for Random Forest", col = "green", lwd = 2)
auc_rf <- auc(roc_rf)
print(paste("Random Forest Validation AUC:", round(auc_rf, 3)))

# Summary Table of AUC Metrics
auc_summary <- data.frame(
  Model = c("Logistic Regression", "Probit Regression", "SVM", "Classification Tree", "Random Forest"),
  Validation_AUC = c(auc_logit, auc_probit, auc_svm, auc_tree, auc_rf)
)
print(auc_summary)

# Final Test Set Evaluation for Best Model
test_rf_probs <- predict(rf_model, newdata = Test, type = "prob")[, "Yes"]
test_rf_pred <- ifelse(test_rf_probs > 0.5, "Yes", "No")
test_rf_pred <- factor(test_rf_pred, levels = c("No", "Yes"))

conf_matrix_test_rf <- confusionMatrix(test_rf_pred, Test$SOUSED, positive = "Yes")
print(conf_matrix_test_rf)

roc_test_rf <- roc(Test$SOUSED, test_rf_probs, levels = c("No", "Yes"))
plot(roc_test_rf, main = "ROC Curve for Random Forest on Test Set", col = "blue", lwd = 2)
auc_test_rf <- auc(roc_test_rf)
print(paste("Random Forest Test AUC:", round(auc_test_rf, 3)))

######################## VISUALS

library(ggcorrplot)
numeric_vars <- df %>% select_if(is.numeric)
cor_matrix <- cor(numeric_vars, use = "complete.obs")
ggcorrplot(cor_matrix, method = "circle", type = "lower", lab = TRUE, 
           title = "Correlation Matrix Heatmap", colors = c("red", "white", "blue"))

ggplot(df, aes(x = SOUSED)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Class Distribution of Solar Usage", x = "Solar Usage", y = "Count")

# Combine ROC Curves for Logistic, Probit, SVM, Classification Tree, and Random Forest
plot(roc_logit, col = "blue", main = "ROC Curves for Classification Models", lwd = 2)
lines(roc_probit, col = "red", lwd = 2)
lines(roc_svm, col = "purple", lwd = 2)
lines(roc_tree, col = "orange", lwd = 2)
lines(roc_rf, col = "green", lwd = 2)
legend("bottomright", legend = c("Logistic", "Probit", "SVM", "Tree", "Random Forest"), 
       col = c("blue", "red", "purple", "orange", "green"), lty = 1, lwd = 2)

varImpPlot(rf_model, main = "Random Forest Feature Importance")

rpart.plot(tree_model, main = "Classification Tree", type = 2, extra = 104)

library(precrec)
pr <- evalmod(scores = valid_logit_probs, labels = as.numeric(Valid$SOUSED) - 1)
autoplot(pr)

library(ggplot2)
cm <- as.data.frame(conf_matrix_logit$table)
ggplot(cm, aes(Prediction, Reference, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "white") +
  labs(title = "Confusion Matrix Heatmap", x = "Predicted", y = "Actual")

cor_target <- cor(numeric_vars, as.numeric(df$SOUSED) - 1, use = "complete.obs")
barplot(cor_target, main = "Correlation with Target", las = 2)
